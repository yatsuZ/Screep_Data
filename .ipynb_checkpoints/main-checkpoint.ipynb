{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3e44dd-b4e2-42e3-9cbb-1302143077ab",
   "metadata": {},
   "source": [
    "voici un lien explicatiffe [pour le travaille :)](https://youtu.be/dQw4w9WgXcQ)\n",
    "non je rigole XD bref de plaisenterie.\n",
    "\n",
    "# Scraping d'allocine\n",
    "\n",
    "![image de presentation de scraping](https://files.realpython.com/media/Build-a-Web-Scraper-With-Requests-and-Beautiful-Soup_Watermarked.37918fb3906c.jpg)\n",
    "\n",
    "## Membre du Projet\n",
    "| Nom   / surnom        | Rôle         |\n",
    "|----------------|----------------|\n",
    "| Yassine Zaoui / yatsu     | Développeur   |\n",
    "| Shiek / le petit scientifique   | Développeur   |\n",
    "\n",
    "# BUT :\n",
    "\n",
    "1. recuperer les de la page d'allocine contenant les fim dans cette [page](https://www.allocine.fr/films/) \n",
    "    recuperer :\n",
    "    0. l'ID\n",
    "    1. le titre\n",
    "    2. Date de sortie\n",
    "    3. Duree du film\n",
    "    4. Type (fantastique, aventure , action)\n",
    "    5. Realisateur\n",
    "    6. Acteur\n",
    "    7. Synopsys\n",
    "    8. Note Presse\n",
    "    9. Note Spectateur\n",
    "    10. Affiche du film\n",
    "2. metre les information dans un csv\n",
    "3. puis dans une base de donne dans une vm\n",
    "4. faire des graphique de quoi jsp encore :/\n",
    "\n",
    "# Structure du rangement des dossier et fichier\n",
    "\n",
    "- le dossier test contient plusieur petit test de programme / fonction pour voir ce qu'on le garde au final\n",
    "___\n",
    "\n",
    "### les Bibliotheque importer son :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9498633f-c94a-45b5-b209-21effcb9470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a336e9-dc23-4783-a7ed-3b2251cb8066",
   "metadata": {
    "tags": []
   },
   "source": [
    "- \"**request**\" permet de faire des requette a la page\n",
    "- \"**beautifulSoup**\" Permet de manipuler des fichier html ou xml\n",
    "- \"**time**\" Permet de faire un temp de pause pour la recolte des donne\n",
    "\n",
    "---\n",
    "#### Fonction manipulation de string a utilise pour plus tard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b9499dd7-7198-450a-b40c-76236ae73585",
   "metadata": {},
   "outputs": [],
   "source": [
    "######- manipulation de string pour recuperer les dates time et les categories -#############\n",
    "def extract_time_and_categories(text):\n",
    "    parts = text.split(\"\\n\")\n",
    "    date = parts[1].strip()\n",
    "    time = parts[3].strip()\n",
    "    categories = parts[5:]\n",
    "    return date, time, categories\n",
    "######- manipulation de string pour recuperer les acteurs -#################################\n",
    "def extract_Acteurs(text):\n",
    "    text = text[5:]\n",
    "    realisateur = \"\"\n",
    "    for i in text :\n",
    "        if (i != \"\\n\"):\n",
    "            realisateur += i\n",
    "        else :\n",
    "            realisateur += \" \"\n",
    "    return realisateur[: -1]\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b606b-be2f-4e11-a8a8-09ed2add196a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Scrapper :\n",
    "\n",
    "Cree une fonction qui me retourne un tab d'un tableau content les infomation shouaite \n",
    "\n",
    "# Constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6e1d2189-35c4-42ff-b4c0-6a3e2bf19658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l' url du lien que je veux scraper\n",
    "url = 'https://www.allocine.fr/films/'\n",
    "#je recupere la page et elle est en requeste\n",
    "response = requests.get(url)\n",
    "\n",
    "#soup = au body de ma page interprete en html\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797e305-5c58-4c07-a3bb-381e02bafd1c",
   "metadata": {},
   "source": [
    "## Code Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61c9b92f-cce9-4fab-ad19-b7ec8c6ce9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################- 1\n",
    "def get_all_Note(presentation):\n",
    "    notes = presentation.find_all(\"span\", \"stareval-note\")\n",
    "    return notes[0].text, notes[1].text\n",
    "############################################################- 2\n",
    "def get_all_Acteur(presentation):\n",
    "    acteurs = presentation.find(\"div\", \"meta-body-item meta-body-actor\")\n",
    "    if acteurs is None:\n",
    "        return \"\"\n",
    "    acteurs = acteurs.text\n",
    "    return extract_Acteurs(acteurs)\n",
    "############################################################- 3\n",
    "def get_all_realisateurs(presentation):\n",
    "    realisateursBalise = presentation.find(\"div\", \"meta-body-item meta-body-direction\")\n",
    "    realisateursSpan = realisateursBalise.find_all(\"span\")[1:]\n",
    "    realisateursA = realisateursBalise.find_all(\"a\")\n",
    "    realisateurs = \"\"\n",
    "    for nom in realisateursA:\n",
    "        realisateurs += nom.text + \", \"\n",
    "    for nom in realisateursSpan:\n",
    "        realisateurs += nom.text + \", \"\n",
    "    return realisateurs[: -2]\n",
    "############################################################- 4\n",
    "def get_all_date_time_categories(presentation):\n",
    "    div = presentation.find(\"div\", \"meta-body-item meta-body-info\").text\n",
    "    date, time, categories = extract_time_and_categories(div)\n",
    "    categories = \" \".join(categories)\n",
    "    return date, time, categories\n",
    "###########################################################- 5\n",
    "def get_photo(presentation):\n",
    "    photo = presentation.find(\"img\", \"thumbnail-img\")\n",
    "    key = photo.get(\"data-src\")\n",
    "    if key is not None:\n",
    "        photo = presentation.find(\"img\", \"thumbnail-img\")['data-src']\n",
    "    else :\n",
    "        photo = presentation.find(\"img\", \"thumbnail-img\")['src']\n",
    "    return photo\n",
    "###########################################################- 6\n",
    "def get_synopsys(presentation):\n",
    "    synopsys = presentation.find(\"div\", \"content-txt\")\n",
    "    if synopsys is None:\n",
    "        return \"\"\n",
    "    synopsys = synopsys.text\n",
    "    synopsys = synopsys[: -1]\n",
    "    return synopsys\n",
    "###########################################################- 7\n",
    "def affichage_data(i, titre, photo, date, time, categories, realisateurs, acteurs, synopsys, notePresse, notePublique, url):\n",
    "    print(\"URL = \"+ url, \"\\nID = \" + str(i),\"\\ntitre = \" + titre, \"\\nimage = \" + photo, \"\\ndate = \" + date, \"\\ntime = \" + time, \"\\ncategorie = \" + categories)\n",
    "    print(\"Realisateur = \" + realisateurs, \"\\nActeur = \" + acteurs, \"\\nSynopsys = \" + synopsys, \"\\nNotePresse = \" + notePresse)\n",
    "    print(\"NotePublique = \" + notePublique, \"\\n-------------------\")\n",
    "##########################################################- 8\n",
    "def get_next_page(nbr_of_page):\n",
    "    if nbr_of_page > 7575:\n",
    "        return None\n",
    "    new_url = 'https://www.allocine.fr/films/' + \"?page=\" + str(nbr_of_page)\n",
    "    response = requests.get(new_url)\n",
    "    page =BeautifulSoup(response.text, 'html.parser')\n",
    "    return page, new_url\n",
    "#########################################################- 9\n",
    "def get_all_presentation_of_this_page(page):\n",
    "    all_presentations_of_this_page = page.find_all(\"div\", class_=\"card entity-card entity-card-list cf\")\n",
    "    #tout les elment que je shouaite scrap on tousse la meme structure et son tout dans une dic qui a \n",
    "    #comme class card entity-card entity-card-list cf\n",
    "    return all_presentations_of_this_page\n",
    "############################################################- Tout avoir\n",
    "\n",
    "def get_all_data_movie(all_presentations_of_this_page, ID, nbr_of_movie, url):\n",
    "    for presentation in all_presentations_of_this_page:\n",
    "        notePresse, notePublique = get_all_Note(presentation)\n",
    "        ###########################################################\n",
    "        synopsys = get_synopsys(presentation)\n",
    "        ###########################################################\n",
    "        acteurs = get_all_Acteur(presentation)\n",
    "        ###########################################################\n",
    "        realisateurs = get_all_realisateurs(presentation)\n",
    "        ###########################################################\n",
    "        date, time, categories = get_all_date_time_categories(presentation)\n",
    "        ###########################################################\n",
    "        photo = get_photo(presentation)\n",
    "        ###########################################################\n",
    "        titre = presentation.find(\"a\", \"meta-title-link\").text\n",
    "        ###########################################################\n",
    "        affichage_data(ID, titre, photo, date, time, categories, realisateurs, acteurs, synopsys, notePresse, notePublique, url)\n",
    "        if nbr_of_movie <= ID:\n",
    "            return -1\n",
    "        ###########################################################\n",
    "        ID = ID + 1\n",
    "    return ID\n",
    "############################################################- Combien de page\n",
    "\n",
    "def get_all_data_from_movie(nbr_of_movie):\n",
    "    ID = 0\n",
    "    nbr_of_page = 1\n",
    "    while (ID != -1):\n",
    "        page, url = get_next_page(nbr_of_page)\n",
    "        all_presentations_of_this_page = get_all_presentation_of_this_page(page)\n",
    "        ID = get_all_data_movie(all_presentations_of_this_page, ID, nbr_of_movie, url)\n",
    "        nbr_of_page += 1\n",
    "        if (nbr_of_page % 10 == 0):\n",
    "            time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a476c49-2934-4efe-a60a-3e0eb11e870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_data_from_movie(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
